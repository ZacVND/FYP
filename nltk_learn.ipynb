{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This is for learning and testing of NLTK module in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, glob, os, bs4, urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "ate was a single man , who lived to a very advanced age , and who for many years\n",
      "een made amiable himself ; for he was very young when he married , and very fond\n",
      " was very young when he married , and very fond of his wife . But Mrs . John Das\n",
      "rosity to so large an amount . It was very well known that no affection was ever\n",
      "hy , to be sure ,\" said her husband , very gravely , \" that would make great dif\n",
      "family , for instance , it would be a very convenient addition .\" \" To be sure i\n",
      "pounds on their mother ' s death -- a very comfortable fortune for any young wom\n",
      "nd if they do not , they may all live very comfortably together on the interest \n",
      "t of ten thousand pounds .\" \" That is very true , and , therefore , I do not kno\n",
      " annuity to be paid them ; and she is very stout and healthy , and hardly forty \n",
      " , and hardly forty . An annuity is a very serious business ; it comes over and \n",
      "low them any thing yearly . It may be very inconvenient some years to spare a hu\n",
      "othing farther ; indeed , it would be very strange and unreasonable if he did . \n",
      "t some of the plate would have been a very pleasant addition to our own stock he\n",
      " nor attention to his wishes ; for we very well know that if he could , he would\n",
      "ntions . The contempt which she had , very early in their acquaintance , felt fo\n",
      "elt for her daughter - in - law , was very much increased by the farther knowled\n",
      " the eldest son of a man who had died very rich ; and some might have repressed \n",
      "der it with some surprise . Edward is very amiable , and I love him tenderly . B\n",
      "though he admires Elinor ' s drawings very much , it is not the admiration of a \n",
      "earning , I think he would have drawn very well . He distrusts his own judgment \n",
      "by the drawings of other people , was very far from that rapturous delight , whi\n",
      " What say you , Marianne ?\" \" I shall very soon think him handsome , Elinor , if\n",
      "g of him . She felt that Edward stood very high in her opinion . She believed th\n",
      " to deny ,\" said she , \" that I think very highly of him -- that I greatly estee\n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"very\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count(\"lol\")\n",
    "100*text5.count(\"lol\") / len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(filename,verbose=True):\n",
    "    '''\n",
    "    preprocesses the .xml file in path 'filename', saved in the format\n",
    "    returned by takeAbstract.take\n",
    "    returns a list of dictionaries of token features, one for each token\n",
    "    in the text\n",
    "    '''\n",
    "    \n",
    "    # opens, processes the file, tokenises in sentences and retrieves\n",
    "    # paragraph labels and categories\n",
    "    f = open(filename).read()\n",
    "    soup = bs4.BeautifulSoup(f,\"html5lib\")\n",
    "    title = take_title(soup.pmid.text)\n",
    "    title = title.decode('utf-8')\n",
    "    print(title)\n",
    "    title = [w.lower() for w in nltk.word_tokenize(normalise_sentence(title))]\n",
    "    if len(soup.abstracttext.attrs)==0:\n",
    "        soup.abstracttext['label'] = 'None'\n",
    "        soup.abstracttext['nlmcategory'] = 'None'        \n",
    "    \n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_title(pmid):\n",
    "    '''\n",
    "    returns the title of the document registered with pmid\n",
    "    :param pmid:str\n",
    "    '''\n",
    "    url = 'http://www.ncbi.nlm.nih.gov/pubmed/'+pmid+'?report=xml&format=text'\n",
    "    print(url)\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', url)\n",
    "    print(\"Request Status: {}\".format(response.status))\n",
    "    xmlpage = response.data.decode('utf-8')\n",
    "    xmlpage = xmlpage.replace('&lt;','<')\n",
    "    xmlpage = xmlpage.replace('&gt;','>')\n",
    "    soup = bs4.BeautifulSoup(xmlpage,\"html5lib\")\n",
    "    if soup.articletitle:\n",
    "        return soup.articletitle.text.encode('utf-8')\n",
    "    else:\n",
    "        return 'no title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.ncbi.nlm.nih.gov/pubmed/10599663?report=xml&format=text\n",
      "Request Status: 200\n",
      "Randomized clinical trial of the 350-mm2 versus the 500-mm2 Baerveldt implant: longer term results: is bigger better?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normalise_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e7eea931c574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxml_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"./new_data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"*.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreprocess_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-84f857cd3a43>\u001b[0m in \u001b[0;36mpreprocess_file\u001b[0;34m(filename, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalise_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstracttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstracttext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'None'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalise_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "xml_dir = r\"./new_data/\"\n",
    "for file in glob.glob(xml_dir + \"*.xml\"):\n",
    "    preprocess_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
